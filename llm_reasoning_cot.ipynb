{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "8FBaagwoomaR"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201524495/201524495/blob/main/llm_reasoning_cot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# LLM Reasoning Lab (CoT · GRPO)\n",
        "실습 내용:\n",
        "- **Chain-of-Thought (CoT)**: zero-shot / few-shot / CoT 프롬프트 사용 및 모델 성능 비교\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TQu5nYUKmk38"
      },
      "id": "TQu5nYUKmk38"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbd7A8dq7MK3"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 필요한 것만 설치하세요\n",
        "# !pip install -q openai\n",
        "# !pip install -q huggingface_hub\n",
        "\n",
        "import os, random, numpy as np\n",
        "USE_PROVIDER = os.getenv(\"USE_PROVIDER\", \"openai\")\n",
        "\n",
        "# === TODO: 키 설정  ===\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\n",
        "\n",
        "# 기본 모델\n",
        "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
        "\n",
        "TEMPERATURE = float(os.getenv(\"TEMPERATURE\", \"0.2\"))\n",
        "MAX_TOKENS = int(os.getenv(\"MAX_TOKENS\", \"1000\"))\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n"
      ],
      "id": "vbd7A8dq7MK3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fexQYZJ-7MK5"
      },
      "source": [
        "## 1) LLM 호출 래퍼 (OpenAI API)\n",
        "로그인 후 API key 발급\n",
        "\n",
        "https://openai.com/ko-KR/index/openai-api/"
      ],
      "id": "fexQYZJ-7MK5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2hEC8oS7MK6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "def format_messages(messages: List[Dict[str, str]]) -> str:\n",
        "    \"\"\"messages 리스트를 사람이 읽기 좋은 문자열로 변환\"\"\"\n",
        "    formatted = []\n",
        "    for m in messages:\n",
        "        role = m.get(\"role\", \"\")\n",
        "        content = m.get(\"content\", \"\")\n",
        "        # content가 list인 경우 처리\n",
        "        if isinstance(content, list):\n",
        "            text_parts = [c.get(\"text\", \"\") for c in content if isinstance(c, dict) and c.get(\"type\") == \"text\"]\n",
        "            content = \"\\n\".join(text_parts)\n",
        "        formatted.append(f\"{role.upper()}:\\n{content.strip()}\\n\")\n",
        "    return \"\\n\".join(formatted)\n",
        "\n",
        "\n",
        "def run_model(messages: List[Dict[str,str]],\n",
        "              temperature: float = TEMPERATURE,\n",
        "              max_tokens: int = MAX_TOKENS,\n",
        "              provider: str = USE_PROVIDER, debug=False) -> str:\n",
        "      # OpenAI SDK (>=1.0)\n",
        "      if debug:\n",
        "          print(\"=== Model Input ===\")\n",
        "          print(format_messages(messages))\n",
        "          print(\"===================\\n\")\n",
        "\n",
        "      try:\n",
        "          from openai import OpenAI\n",
        "          client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "          # Prefer Responses API; fallback to Chat Completions\n",
        "          try:\n",
        "              resp = client.responses.create(\n",
        "                  model=OPENAI_MODEL,\n",
        "                  input=messages,\n",
        "                  temperature=temperature,\n",
        "                  max_output_tokens=max_tokens,\n",
        "              )\n",
        "\n",
        "              # Extract plain text\n",
        "              for item in resp.output:\n",
        "                  if item.type == \"message\":\n",
        "                      for c in item.content:\n",
        "                          if c.type == \"output_text\":\n",
        "                              if debug:\n",
        "                                  print(\"=== Model Output (OpenAI Responses API) ===\")\n",
        "                                  print(c.text)  # 전체 응답 객체 출력\n",
        "                                  print(\"===========================================\\n\")\n",
        "                                  return\n",
        "                              return c.text\n",
        "\n",
        "\n",
        "              return str(resp)\n",
        "          except Exception:\n",
        "              chat = client.chat.completions.create(\n",
        "                  model=OPENAI_MODEL,\n",
        "                  messages=messages,\n",
        "                  temperature=temperature,\n",
        "                  max_tokens=max_tokens,\n",
        "              )\n",
        "              return chat.choices[0].message.content\n",
        "      except Exception as e:\n",
        "          return f\"[OpenAI error] {e}\""
      ],
      "id": "r2hEC8oS7MK6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJAIOcjf7MK7"
      },
      "source": [
        "## 2) 미니 데이터셋 (10문제)\n"
      ],
      "id": "tJAIOcjf7MK7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVAyFZlE7MK8"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "DATA = [\n",
        "    {\"id\": 1, \"question\": \"3 red apples and 5 green apples. You eat 2 green apples. How many apples are left?\", \"answer\": \"6\"},\n",
        "    {\"id\": 2, \"question\": \"Tom has 12 candies and gives 3 to Sara and 4 to Jim. How many candies now?\", \"answer\": \"5\"},\n",
        "    {\"id\": 3, \"question\": \"A train travels 60 km in 1 hour. How far in 3 hours?\", \"answer\": \"180\"},\n",
        "    {\"id\": 4, \"question\": \"If a dozen eggs cost $6, how much do 3 dozens cost?\", \"answer\": \"18\"},\n",
        "    {\"id\": 5, \"question\": \"Jenny read 15 pages on Mon and 23 on Tue. She wants 50 total. Pages left?\", \"answer\": \"12\"},\n",
        "    {\"id\": 6, \"question\": \"There are 10 oranges. You buy 7 more and give away 5. How many now?\", \"answer\": \"12\"},\n",
        "    {\n",
        "        \"id\": 7,\n",
        "        \"question\": \"An item costs 15,000 won. A 10% discount is applied, then a 10% tax is added on the discounted price. What is the final price (won)?\",\n",
        "        \"answer\": \"14850\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 8,\n",
        "        \"question\": \"A student’s average after 4 tests is 82. What score is needed on the 5th test to raise the average to 85?\",\n",
        "        \"answer\": \"97\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 9,\n",
        "        \"question\": \"Worker A can finish a job in 10 hours, and B in 5 hours. They work together for 2 hours, then B leaves. How many more hours does A need to finish?\",\n",
        "        \"answer\": \"4\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 10,\n",
        "        \"question\": \"You have 6 liters of a 25% acid solution. How many liters of water must be added to make it a 15% solution?\",\n",
        "        \"answer\": \"4\"\n",
        "    },\n",
        "]"
      ],
      "id": "KVAyFZlE7MK8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkaVA7ca7MK-"
      },
      "source": [
        "## 3) Zero-shot / Few-shot / CoT\n"
      ],
      "id": "PkaVA7ca7MK-"
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"You are a helpful reasoning assistant. Always answer with the final numeric answer only.\"\n",
        "q = DATA[0]['question']\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},\n",
        "                {\"role\":\"user\",\"content\":q}]\n",
        "\n",
        "messages"
      ],
      "metadata": {
        "id": "lDAX7ZLZbsy5"
      },
      "id": "lDAX7ZLZbsy5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(format_messages(messages))"
      ],
      "metadata": {
        "id": "El_l53t3b0fJ"
      },
      "id": "El_l53t3b0fJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTxzyA37MK_"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def ask_zero_shot(q: str, debug=False):\n",
        "    messages = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},\n",
        "                {\"role\":\"user\",\"content\":q}]\n",
        "\n",
        "    return run_model(messages, debug=debug)\n",
        "\n",
        "FEW_SHOTS = [\n",
        "    {\"role\":\"user\",\"content\":\"There are 2 apples and 3 oranges. Total?\"},\n",
        "    {\"role\":\"assistant\",\"content\":\"5\"},\n",
        "    {\"role\":\"user\",\"content\":\"You had 10 candies and gave 4 away. How many now?\"},\n",
        "    {\"role\":\"assistant\",\"content\":\"6\"},\n",
        "]\n",
        "\n",
        "def ask_few_shot(q: str, debug=False):\n",
        "    ## ToDo: few-shot prompt 구현\n",
        "    msgs = None\n",
        "    return run_model(msgs, debug=debug)\n"
      ],
      "id": "PsTxzyA37MK_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6epxzzMA7MLA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import re\n",
        "COT_PROMPT = \"\"\"\n",
        "Solve the problem step by step. Show your reasoning.\n",
        "Return the final numeric answer after the tag <final> like: <final>ANSWER</final>.\n",
        "\"\"\"\n",
        "def extract_final(text: str) -> str:\n",
        "    m = re.search(r\"<final>\\s*(.*?)\\s*</final>\", text, flags=re.I|re.S)\n",
        "    return m.group(1).strip() if m else text.strip()\n",
        "\n",
        "def ask_cot(q: str, debug=False):\n",
        "    ## ToDo: CoT prompt 구현\n",
        "    msgs = None\n",
        "    return run_model(messages, debug=debug)\n"
      ],
      "id": "6epxzzMA7MLA"
    },
    {
      "cell_type": "code",
      "source": [
        "print(DATA[0]['question'])"
      ],
      "metadata": {
        "id": "6skch53GARSZ"
      },
      "id": "6skch53GARSZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zero-shot response\n",
        "ask_zero_shot(DATA[0]['question'], debug=True)"
      ],
      "metadata": {
        "id": "WHgAh3t8_RD6"
      },
      "id": "WHgAh3t8_RD6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# few-shot response (in-context learning)\n",
        "ask_few_shot(DATA[0]['question'], debug=True)"
      ],
      "metadata": {
        "id": "Q_DGmrkBBTAf"
      },
      "id": "Q_DGmrkBBTAf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CoT response\n",
        "ask_cot(DATA[0]['question'], debug=True)"
      ],
      "metadata": {
        "id": "aYWXe0zgAc8p"
      },
      "id": "aYWXe0zgAc8p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVpOYT5v7MLA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "def evaluate(fn):\n",
        "    preds, golds = [], []\n",
        "    for ex in DATA:\n",
        "        out = fn(ex[\"question\"])\n",
        "        if fn.__name__ in (\"ask_cot\",\"ask_structured\",\"ask_react\"):\n",
        "            out = extract_final(out)\n",
        "        preds.append(out.strip()); golds.append(ex[\"answer\"].strip())\n",
        "    acc = mean([p==g for p,g in zip(preds,golds)])\n",
        "    return acc, list(zip([d[\"id\"] for d in DATA], preds, golds))\n"
      ],
      "id": "MVpOYT5v7MLA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0qTQspy7MLA"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 예시 실행\n",
        "acc0, _ = evaluate(ask_zero_shot)\n",
        "acc1, _ = evaluate(ask_few_shot)\n",
        "acc2, _ = evaluate(ask_cot)\n",
        "print(acc0, acc1, acc2)\n"
      ],
      "id": "V0qTQspy7MLA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정답"
      ],
      "metadata": {
        "id": "8FBaagwoomaR"
      },
      "id": "8FBaagwoomaR"
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_few_shot(q: str, debug=False):\n",
        "    msgs = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT}] + FEW_SHOTS + [{\"role\":\"user\",\"content\":q}]\n",
        "    return run_model(msgs, debug=debug)\n",
        "\n",
        "\n",
        "def ask_cot(q: str, debug=False):\n",
        "    messages = [{\"role\":\"system\",\"content\":\"You are a helpful reasoning assistant.\"},\n",
        "                {\"role\":\"user\",\"content\": q + \"\\n\\n\" + COT_PROMPT}]\n",
        "    return run_model(messages, debug=debug)\n"
      ],
      "metadata": {
        "id": "1-IYmTZToMwE"
      },
      "id": "1-IYmTZToMwE",
      "execution_count": null,
      "outputs": []
    }
  ]
}