{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201524495/201524495/blob/main/incontext_learning_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116567ed",
      "metadata": {
        "id": "116567ed"
      },
      "source": [
        "\n",
        "# Zero/Few-shot In-context Learning 실습 노트북\n",
        "**작성일**: 2025-07-18 by Yeongtak Oh (Credit : DSAIL LAb, SNU)\n",
        "\n",
        "**목표**:  \n",
        "- Zero-shot 및 Few-shot 학습 방식 이해  \n",
        "- Chain-of-Thought 및 Tool-use 프롬프트 실습  \n",
        "- 사용자 입력 기반 인터랙션 실습  \n",
        "- 결과 CSV 저장, 체크리스트, 퀴즈 포함\n",
        "\n",
        "---\n",
        "> 본 노트북은 HD현대 실습을 위해 교육용 자료로서 준비되었으며, PyTorch와 HuggingFace Transformers 라이브러리를 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e695b355",
      "metadata": {
        "id": "e695b355"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets ipywidgets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e94f83d",
      "metadata": {
        "id": "9e94f83d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        " # https://huggingface.co/gpt2-medium\n",
        "model_name = \"gpt2-medium\" # \"Qwen/Qwen3-0.6B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "model.eval()\n",
        "\n",
        "log = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433ba523",
      "metadata": {
        "id": "433ba523"
      },
      "outputs": [],
      "source": [
        "def generate_completion(prompt, max_new_tokens=50):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    output = tokenizer.decode(output_ids[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "    log.append({\"prompt\": prompt, \"response\": output})\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e63227",
      "metadata": {
        "id": "91e63227"
      },
      "source": [
        "\n",
        "## 실습 체크리스트\n",
        "\n",
        "- 1) Zero-shot 번역 실습 실행  \n",
        "- 2) Few-shot 번역 실습 실행  \n",
        "- 3) 감정 분석 예제 실행  \n",
        "- 4) 사용자 직접 프롬프트 실습  \n",
        "- 5) Chain-of-Thought 예제 실행  \n",
        "- 6) Tool-use 예제 실행  \n",
        "- 결과를 CSV로 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a96587",
      "metadata": {
        "id": "41a96587"
      },
      "outputs": [],
      "source": [
        "# zero-shot은 demonstration x\n",
        "print(\"Zero-shot 예제\")\n",
        "prompt = \"Translate English to French: I like pizza.\"\n",
        "print(\"Prompt:\", prompt)\n",
        "print(\"Generated:\", generate_completion(prompt))\n",
        "\n",
        "# few-shot은 demonstration o\n",
        "print(\"\\n Few-shot 예제\")\n",
        "few_shot = (\n",
        "    \"Translate English to French:\\n\"\n",
        "    \"English: Hello.\\nFrench: Bonjour.\\n\"\n",
        "    \"English: Good night.\\nFrench: Bonne nuit.\\n\"\n",
        "    \"English: I like pizza.\\nFrench:\"\n",
        ")\n",
        "print(\"Prompt:\\n\", few_shot)\n",
        "print(\"Generated:\", generate_completion(few_shot))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48b63c07",
      "metadata": {
        "id": "48b63c07"
      },
      "outputs": [],
      "source": [
        "# example 1: sentimental analysis\n",
        "print(\"\\n 감정 분석 Few-shot\")\n",
        "emotion_prompt = (\n",
        "    \"Tweet: I hate everything.\\nSentiment: Negative\\n\"\n",
        "    \"Tweet: I love sunshine.\\nSentiment: Positive\\n\"\n",
        "    \"Tweet: I want to cry.\\nSentiment:\"\n",
        ")\n",
        "print(generate_completion(emotion_prompt))\n",
        "\n",
        "# CoT example\n",
        "print(\"\\n Chain-of-Thought 예제\")\n",
        "cot = (\n",
        "    \"Q: If a train has 5 cars and each car has 20 people, how many total people?\\n\"\n",
        "    \"A: Let's think step by step. Each car has 20 people. There are 5 cars. So 5 * 20 = 100. Answer: 100\"\n",
        "    \"\\n\\nQ: There are 3 boxes. Each box has 4 apples. How many apples?\\nA:\"\n",
        ")\n",
        "print(generate_completion(cot))\n",
        "\n",
        "# Tool use example\n",
        "print(\"\\n Tool-use 예제\")\n",
        "tool_prompt = (\n",
        "    \"Question: What is 15 * 12?\\n\"\n",
        "    \"Let's use a calculator: 15 * 12 = 180.\\nAnswer: 180\\n\"\n",
        "    \"Question: What is 9 * 11?\\nLet's use a calculator:\"\n",
        ")\n",
        "print(generate_completion(tool_prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b0bec8",
      "metadata": {
        "id": "73b0bec8"
      },
      "outputs": [],
      "source": [
        "# With on your own prompts (PLAYGROUND)\n",
        "prompt_input = widgets.Textarea(\n",
        "    value='Input your prompt here...',\n",
        "    placeholder='Enter any instruction or query',\n",
        "    description='Prompt:',\n",
        "    layout=widgets.Layout(width='100%', height='100px')\n",
        ")\n",
        "button = widgets.Button(description='Generate')\n",
        "output = widgets.Output()\n",
        "\n",
        "@output.capture()\n",
        "def on_click(b):\n",
        "    output.clear_output()\n",
        "    prompt = prompt_input.value\n",
        "    result = generate_completion(prompt)\n",
        "    print(\"Generated:\", result)\n",
        "\n",
        "button.on_click(on_click)\n",
        "display(prompt_input, button, output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c78dc4c",
      "metadata": {
        "id": "3c78dc4c"
      },
      "outputs": [],
      "source": [
        "# Output save files\n",
        "df = pd.DataFrame(log)\n",
        "df.to_csv(\"incontext_outputs.csv\", index=False)\n",
        "print(\"💾 Saved as incontext_outputs.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40e4182",
      "metadata": {
        "id": "c40e4182"
      },
      "source": [
        "\n",
        "## 📝 퀴즈 (5분)\n",
        "\n",
        "1. Zero-shot learning과 Few-shot learning의 차이를 서술하시오.  \n",
        "2. Chain-of-Thought prompting이 모델 성능 향상에 어떤 영향을 미치는가?  \n",
        "3. Tool-use prompting의 한계점은 무엇인가?\n",
        "\n",
        "> 답안은 아래 셀에 작성하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaeac057",
      "metadata": {
        "id": "eaeac057"
      },
      "outputs": [],
      "source": [
        "# 여기에 작성하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 답변  \n",
        "\n",
        "#### 1. **Zero-shot learning vs. Few-shot learning**  \n",
        "- **Zero-shot learning**:  \n",
        "  - 모델이 **학습 시 특정 태스크나 데이터를 경험하지 않았음에도**, **추론 시 단일 예시 없이** 새로운 태스크를 수행하는 방식입니다.  \n",
        "  - 예: \"이 문장은 긍정적입니까? 부정적입니까?\"와 같이 **명시적 예시 없이** 분류를 요청.  \n",
        "  - **장점**: 데이터 부족 환경에서 유연성 제공.  \n",
        "  - **단점**: 복잡한 태스크에서는 성능 저하 가능성.  \n",
        "\n",
        "- **Few-shot learning**:  \n",
        "  - **1~몇 개의 예시**를 제공하여 모델이 패턴을 학습하게 하는 방식입니다.  \n",
        "  - 예: \"긍정: '좋은 제품입니다!', 부정: '불만족스러웠습니다.' → '이 서비스는 훌륭합니다!'는 어떤가요?\"  \n",
        "  - **장점**: 예시를 통해 성능 향상 가능.  \n",
        "  - **단점**: 예시의 질과 수량에 따라 결과가 변동.  \n",
        "\n",
        "**핵심 차이**: Zero-shot은 **예시 없이**, Few-shot은 **최소한의 예시로** 태스크를 수행합니다.  \n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Chain-of-Thought Prompting의 영향**  \n",
        "- **원리**: 모델에게 **중간 단계의 추론 과정을 명시적으로 설명**하도록 유도합니다.  \n",
        "  - 예: \"이 문제를 푸는 방법을 단계별로 설명해 주세요.\"  \n",
        "- **효과**:  \n",
        "  - **복잡한 태스크**(수학 문제, 논리 추론)에서 정확도 향상.  \n",
        "  - 모델이 **내재된 논리적 구조를 명시적으로 활용**하게 됨.  \n",
        "  - **예측 가능성과 해석성** 증가.  \n",
        "- **제한**:  \n",
        "  - 단순 태스크에서는 과도한 복잡성 유발 가능성.  \n",
        "  - 추론 단계가 잘못 생성될 경우 최종 결과 오류 발생.  \n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Tool-use Prompting의 한계점**  \n",
        "- **정의**: 외부 도구(예: 계산기, API)를 활용해 모델의 답변을 보완하는 방식.  \n",
        "- **한계**:  \n",
        "  1. **도구 의존성**:  \n",
        "     - 도구의 **정확성, 업데이트 상태**에 따라 결과가 변동.  \n",
        "     - 예: 오래된 데이터베이스를 사용하면 실시간 정보 제공 불가.  \n",
        "  2. **통합 복잡성**:  \n",
        "     - 도구와의 **인터페이스 설계**, 오류 처리 등 추가 개발 필요.  \n",
        "  3. **추론 오류**:  \n",
        "     - 모델이 **도구 사용 시점이나 방식을 잘못 판단**할 수 있음.  \n",
        "     - 예: 불필요한 도구 호출로 인한 비효율.  \n",
        "  4. **보안 및 비용**:  \n",
        "     - 외부 API 사용 시 **비용 증가** 또는 **데이터 유출 리스크** 발생.  \n",
        "\n",
        "---\n",
        "\n",
        "### 요약  \n",
        "| 항목 | Zero-shot vs. Few-shot | Chain-of-Thought | Tool-use Prompting |  \n",
        "|------|------------------------|------------------|--------------------|  \n",
        "| **핵심** | 예시 유무에 따른 태스크 수행 | 추론 단계 명시 | 외부 도구 활용 |  \n",
        "| **장점** | 데이터 독립성, 유연성 | 복잡 태스크 성능 향상 | 정확도 보완 |  \n",
        "| **단점** | 성능 불안정, 예시 의존 | 과도한 복잡성 | 도구 의존성, 비용 증가 |  \n",
        "\n"
      ],
      "metadata": {
        "id": "3HMQgcZoHL6H"
      },
      "id": "3HMQgcZoHL6H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BPmggjzZXVmn",
      "metadata": {
        "id": "BPmggjzZXVmn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}