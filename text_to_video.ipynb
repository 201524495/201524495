{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/201524495/201524495/blob/main/text_to_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Text-to-Video Hands‑On\n",
        "\n",
        "이 노트북은 텍스트 프롬프트로 짧은 비디오를 생성해보며, 확산 모델의 핵심 개념을 직접 실습할 수 있게 구성했습니다.\n",
        "\n",
        "구성:\n",
        "1. 빠른 시연 (데모) — 바로 결과 만들어 보기\n",
        "2. 개념 이해 — 확산(diffusion), 스케줄러, CFG, 시드, 프레임 수 등\n",
        "3. **TODO 실습** — 작은 함수/로직을 직접 작성하여 이해도 높이기"
      ],
      "id": "title"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 0) 런타임 설정 및 GPU 확인\n",
        "- \"런타임\" → \"런타임 유형 변경\" → 하드웨어 가속기: **GPU** (T4)\n",
        "- 아래 셀을 실행하여 GPU 인식 및 기본 환경을 확인합니다."
      ],
      "id": "setup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpu-check"
      },
      "outputs": [],
      "source": [
        "import torch, platform, sys, subprocess, os, random\n",
        "print(f\"Python        : {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch avail?: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU name      : {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"CUDA version  : {torch.version.cuda}\")\n",
        "print(f\"Platform      : {platform.platform()}\")\n",
        "if torch.cuda.is_available():\n",
        "    !nvidia-smi -L\n",
        "    !nvidia-smi"
      ],
      "id": "gpu-check"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install"
      },
      "source": [
        "## 1) 의존성 설치\n",
        "Colab 기본 PyTorch를 그대로 쓰고, 필요한 라이브러리만 설치합니다.\n",
        "\n",
        "**설치 패키지**\n",
        "- `diffusers` : 모델 로딩/추론 파이프라인\n",
        "- `transformers`, `accelerate`, `safetensors`\n",
        "- `imageio`, `imageio-ffmpeg` : 비디오 저장\n",
        "- `decord` : 프레임 미리보기"
      ],
      "id": "install"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pip-install"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U diffusers transformers accelerate safetensors imageio imageio-ffmpeg decord"
      ],
      "id": "pip-install"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quick-demo"
      },
      "source": [
        "## 2) Demo\n",
        "`diffusers`의 **ModelScope Text2Video** 파이프라인을 사용합니다.\n",
        "\n",
        "> 만약 VRAM이 부족하면 `num_frames`, `height`, `width`, `num_inference_steps`를 줄이세요."
      ],
      "id": "quick-demo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "demo-run"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch, os\n",
        "from diffusers.utils import export_to_video\n",
        "\n",
        "model_id = \"damo-vilab/text-to-video-ms-1.7b\"\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        ")\n",
        "\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_vae_slicing()\n",
        "pipe.enable_model_cpu_offload()\n",
        "\n",
        "prompt = \"a cute corgi surfing on a tropical wave, cinematic lighting, 4k\"\n",
        "negative_prompt = \"low quality, text, watermark\"\n",
        "seed = 42\n",
        "generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "result = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=25,\n",
        "    num_frames=16,\n",
        "    guidance_scale=9.0,\n",
        "    height=320, width=512,\n",
        "    generator=generator,\n",
        ")\n",
        "frames = result.frames[0]\n",
        "video_path = \"demo_ms_t2v.mp4\"\n",
        "export_to_video(frames, video_path, fps=8)\n",
        "print(f\"Saved: {os.path.abspath(video_path)}\")"
      ],
      "id": "demo-run"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preview"
      },
      "source": [
        "### Demo\n",
        "Colab에서 mp4를 직접 재생합니다."
      ],
      "id": "preview"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display-video"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "def show_video(path):\n",
        "    mp4 = open(path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f\"\"\"\n",
        "    <video width=640 controls><source src='{data_url}' type='video/mp4'></video>\n",
        "    \"\"\")\n",
        "\n",
        "show_video(\"demo_ms_t2v.mp4\")"
      ],
      "id": "display-video"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "todo-build"
      },
      "source": [
        "## 3) 직접 만들기 (TODO 실습)\n",
        "아래 함수/코드를 **TODO**를 채워가며 완성해 보세요. 각 함수는 비교적 짧고, 주석에 힌트가 있습니다.\n",
        "\n",
        "완성 후에는 아래 \"테스트\" 셀로 바로 확인할 수 있습니다."
      ],
      "id": "todo-build"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utils-todos"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "from typing import List\n",
        "\n",
        "def make_generator(seed: int, device: str = \"cuda\"):\n",
        "    \"\"\"TODO: 주어진 seed로 torch.Generator를 생성해 반환하세요.\"\"\"\n",
        "    ### YOUR CODE HERE ###\n",
        "    # hint: torch.Generator(device).manual_seed(seed)\n",
        "    return generator\n",
        "\n",
        "def export_to_mp4(frames: List, path: str, fps: int = 8):\n",
        "    \"\"\"TODO: imageio.get_writer를 사용해 frames를 mp4로 저장하세요.\n",
        "    frames = [frame1, frame2, ... ]\n",
        "    \"\"\"\n",
        "    with imageio.get_writer(path, fps=fps, codec=\"libx264\", macro_block_size=None) as writer:\n",
        "        ### YOUR CODE HERE ###\n",
        "        # array = each frame in frames\n",
        "        # writer.append_data(array)\n",
        "        pass\n",
        "\n",
        "def apply_style(prompt: str, style: str = \"cinematic\") -> str:\n",
        "    \"\"\"TODO: style에 따라 prompt를 가볍게 보강해 반환하세요.\"\"\"\n",
        "\n",
        "    style_map = {\n",
        "        \"cinematic\": \", cinematic lighting, 4k, depth of field, high contrast\",\n",
        "        \"animation\": \", 2d animation, vibrant colors, clean lines\",\n",
        "        \"studio\": \", studio lighting, soft shadows, color graded\",\n",
        "        \"film\": \", 35mm film grain, natural lighting, shallow depth of field\",\n",
        "        \"sketch\": \", pencil sketch, monochrome, line art style\",\n",
        "    }\n",
        "\n",
        "    styled_prompt = None # prompt + additional_style_prompt\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "    return styled_prompt\n",
        "\n",
        "def sweep(values, fn):\n",
        "    return [fn(v) for v in values]"
      ],
      "id": "utils-todos"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pipeline-build"
      },
      "outputs": [],
      "source": [
        "from diffusers import DiffusionPipeline\n",
        "import torch\n",
        "\n",
        "def load_ms_t2v(dtype=torch.float16, cpu_offload=True):\n",
        "    \"\"\"ModelScope Text2Video 파이프라인을 로드합니다.\n",
        "    TODO: dtype/메모리절약 옵션을 인자로 반영하고 return 하세요.\n",
        "    \"\"\"\n",
        "    model_id = \"damo-vilab/text-to-video-ms-1.7b\"\n",
        "\n",
        "    kwargs = {\"torch_dtype\": dtype}\n",
        "    if dtype == torch.float16:\n",
        "        kwargs[\"variant\"] = \"fp16\"\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "    # pipe = DiffusionPipeline.from_pretrained(...)\n",
        "\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_vae_slicing()\n",
        "    if cpu_offload:\n",
        "        pipe.enable_model_cpu_offload()\n",
        "    else:\n",
        "        if torch.cuda.is_available():\n",
        "            pipe.to(\"cuda\")\n",
        "\n",
        "    return pipe\n",
        "\\\n",
        "def generate_video(pipe, prompt: str, negative_prompt: str = None,\n",
        "                   num_frames: int = 16, steps: int = 25, guidance_scale: float = 9.0,\n",
        "                   height: int = 320, width: int = 512, seed: int = 0, fps: int = 8,\n",
        "                   save_path: str = \"output.mp4\"):\n",
        "    \"\"\"파이프라인으로 비디오를 생성하고 파일로 저장한 뒤 경로를 반환합니다.\n",
        "    TODO: make_generator, pipe 호출, export_to_mp4를 사용하세요.\n",
        "    \"\"\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    ### YOUR CODE HERE ###\n",
        "    # gen = ...\n",
        "    # result = pipe(prompt=..., negative_prompt=..., num_inference_steps=..., num_frames=..., guidance_scale=..., height=..., width=..., generator=gen)\n",
        "    # frames = result.frames[0]\n",
        "    # export_to_mp4(frames, save_path, fps=fps)\n",
        "\n",
        "    return save_path"
      ],
      "id": "pipeline-build"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "todo-run-test"
      },
      "outputs": [],
      "source": [
        "pipe = load_ms_t2v()\n",
        "p = apply_style(\"a sleepy cat playing piano\", style=\"cinematic\")\n",
        "out_path = generate_video(pipe, p, negative_prompt=\"low quality, watermark\", seed=123, fps=8)\n",
        "show_video(out_path)"
      ],
      "id": "todo-run-test"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exp-section"
      },
      "source": [
        "## 4) 직접 해보기\n",
        "다음 항목들을 수정해가며 **무엇이 어떻게 바뀌는지** 관찰해 보세요.\n",
        "\n",
        "- `guidance_scale`: 5 ~ 13 사이를 돌려보세요. 너무 크면 부자연스러울 수 있어요.\n",
        "- `num_inference_steps`: 생성 step의 수. 15, 25, 35를 비교해보세요.\n",
        "- `num_frames`: 생성할 프레임의 수.\n",
        "- `height/width`: 256×256, 320×512 등 해상도 변화.\n",
        "- 프롬프트 엔지니어링: 장면, 스타일(수채화, 스톱모션, 저녁 역광 등) 바꿔보기.\n",
        "- **부정 프롬프트**(negative prompt): 텍스트/워터마크/낮은 품질 제거에 도움.\n"
      ],
      "id": "exp-section"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2559f29a",
      "metadata": {
        "id": "2559f29a"
      },
      "outputs": [],
      "source": [
        "pipe = load_ms_t2v()\n",
        "p = apply_style(\"a sleepy cat playing piano\", style=\"cinematic\")\n",
        "demo_path = generate_video(...) # your arguments here\n",
        "show_video(demo_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshoot"
      },
      "source": [
        "## 5) 문제 해결 (Troubleshooting)\n",
        "- **메모리 부족(OOM)**: 프레임/해상도/스텝/가이던스 스케일을 줄이세요. `enable_model_cpu_offload()` 유지.\n",
        "- **느림**: `enable_model_cpu_offload()`는 느려질 수 있습니다. 여유가 되면 끄고 실행해보세요.\n",
        "- **결과가 마음에 들지 않음**: 프롬프트를 구체화하고, 부정 프롬프트로 원치 않는 요소를 제거하세요.\n",
        "- **재현 안 됨**: 시드를 고정하세요.\n"
      ],
      "id": "troubleshoot"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}